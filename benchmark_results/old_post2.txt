https://github.com/lehuyduc/1brc-simd

`1brc_final_valid.cpp` follows all the requirements specified by the challenges (no preprocessing, has to work with all valid inputs length <= 100, no extra input assumption, single-file no libraries, etc).

Tested on file size 13795495846 bytes, generated by `./create_measurements.sh 1000000000`. Tested on many PCs. No HugeTLB.

~**Dual Socket AMD EPYC 9354 3.75 GHz (64c128t total), 768GB 12-channel DDR5 3200MHz**~
**Threadripper PRO 5995WX 64c128t, 256GB DDR4 unknown speed**
Ubuntu 20.04, virtual machine, g++ 9.4. 
Test version: `1brc_valid16`
**Finally broke through 0.4 second total time barrier!!!** Thanks to `munmap` time on 5995WX PC being much faster than on EPYC 9354 PC (190ms vs 220ms). 

```
Using 128 threads
Malloc cost = 0.006652
init mmap file cost = 0.014066ms
Parallel process file cost = 152.155ms
Aggregate stats cost = 2.44852ms
Output stats cost = 0.598279ms
Runtime inside main = 155.241ms
Time to munmap = 194.04
Time to free memory = 9.50263
real    0m0.362s
user    0m15.564s
sys     0m1.081s

Using 64 threads
Malloc cost = 0.006061
init mmap file cost = 0.014647ms
Parallel process file cost = 231.558ms
Aggregate stats cost = 2.32858ms
Output stats cost = 1.14539ms
Runtime inside main = 235.081ms
Time to munmap = 196.901
Time to free memory = 4.66092
real    0m0.440s
user    0m12.055s
sys     0m0.899s

Using 32 threads
Malloc cost = 0.006924
init mmap file cost = 0.020569ms
Parallel process file cost = 386.718ms
Aggregate stats cost = 1.39825ms
Output stats cost = 0.558864ms
Runtime inside main = 388.708ms
Time to munmap = 193.599
Time to free memory = 3.01529
real    0m0.588s
user    0m11.753s
sys     0m0.642s
```

**At 128 threads, the program finishes the challenge faster than the OS can `munmap` the input file.** `munmap` alone takes up over 50% of the time, so it cost more than the program's allocation, initialization, processing, output, and freeing resources all combined. 

With this many threads, aggregating the results from all threads take a noticeable amount of time. So we use parallel processing to speed up that too, saving ~28ms at 128 threads. By using 2 layers of parallel aggregation, we save an extra ~2.5ms lol. 

--------------------
**Found a PC to borrow with the same spec as the official test server (AMD EPYC 7502 CPU, 256GB RAM).** So I also tested top 3 solutions (lowest 10K dataset time on the official leaderboard). For each person, I tested 2 versions: with native binary, and without. I use the code from the official repo, commit 673c1b9

I use OpenJDK-21 Java version:
```
root@C.8317504:~$ java --version
java 21.0.2 2024-01-16 LTS
Java(TM) SE Runtime Environment (build 21.0.2+13-LTS-58)
Java HotSpot(TM) 64-Bit Server VM (build 21.0.2+13-LTS-58, mixed mode, sharing)
```

Run commands below. 10K dataset can be generated by `./create_measurements3.sh 1000000000`. In the raw results file, you can see that GraalVM native binary is built successfully.
```
numactl --physcpubind=0-7 hyperfine --warmup 1 --runs 10 ./main # original, 8 threads
hyperfine --warmup 1 --runs 10 ./main # original, 64 threads
./prepare_artsiomkorzun.sh
numactl --physcpubind=0-7 hyperfine --warmup 1 --runs 10 "./calculate_average_artsiomkorzun.sh 2>&1"
hyperfine --warmup 1 --runs 10 "./calculate_average_artsiomkorzun.sh 2>&1"
```

Table cells contain `Time (mean ± σ)` output from `hyperfine`. **No GraalVM**

| Name/Test  | Original, 8 thread | Original, 64 thread | 10K, 8 thread | 10K, 64 thread |
| ------------- | ------------- | ------------- | ------------- | ------------- |
| lehuyduc  | 1.966 s ±  0.013 s  | 613.0 ms ±   6.3 ms  | 2.718 s ±  0.021 s  | 963.6 ms ±   3.8 ms |
| artsiomkorzun  | 2.488 s ±  0.078 s  | 894.6 ms ±  39.3 ms | 4.168 s ±  0.062 s  | 1.351 s ±  0.015 s  |
| royvanrijn  | 2.998 s ±  0.207 s  | 1.354 s ±  0.058 s  | 5.596 s ±  0.129 s  | 1.908 s ±  0.041 s |
| royvanrijn (ef24d4e) | 2.818 s ±  0.182 s  | 1.207 s ±  0.052 s  | 5.100 s ±  0.079 s  | 1.765 s ±  0.050 s |
| thomaswue  | 2.804 s ±  0.062 s  | 1.180 s ±  0.073 s  | 5.111 s ±  0.044 s  | 2.094 s ±  0.052 s  |

Table cells contain `Time (mean ± σ)` output from `hyperfine`. **With GraalVM**

| Name/Test  | Original, 8 thread | Original, 64 thread | 10K, 8 thread | 10K, 64 thread |
| ------------- | ------------- | ------------- | ------------- | ------------- |
| lehuyduc  | 1.966 s ±  0.013 s  | 613.0 ms ±   6.3 ms  | 2.718 s ±  0.021 s  | 963.6 ms ±   3.8 ms |
| artsiomkorzun  | 2.106 s ±  0.009 s  | 695.7 ms ±   3.4 ms | 2.674 s ±  0.008 s  | 1.037 s ±  0.012 s  |
| royvanrijn  | 3.010 s ±  0.018 s  | 881.9 ms ±   5.8 ms  | 4.898 s ±  0.017 s  | 1.564 s ±  0.014 s |
| thomaswue  | 2.279 s ±  0.021 s  | 666.4 ms ±   8.2 ms  | 4.193 s ±  0.022 s  | 1.480 s ±  0.012 s  |

~~**Everyone's result is much better here compared to official the official test server Hetzner AX161 !!!**~~ Results for `413/64 thread` and `10K/8 thread` are outdated, but `413/8 thread` results are not.

Compared to the last tested commit [2c26b511](https://github.com/gunnarmorling/1brc/commit/2c26b511e741f4d96a51dda831001946ea27a591) 
- @artsiomkorzun `original 64 thread` is 78% faster (1.236 / 695.7), `10K 8 thread` is 72% faster (4.589 / 2.674)
- @thomaswue  `original 64 thread` is 20% faster (799 / 666.4), `10K 8 thread` is 27% faster
- @royvanrijn  `original 64 thread` is 6% faster, `10K 8 thread` is 8% faster

On this PC, time to `munmap` is around 210ms for default dataset, and 255ms for 10K dataset (measured in C++ version). But since `munmap` is done by the OS and no solutions implement fast `munmap`, we can assume it's the same between all implementations. So we exclude `munmap` time to see how much time is spent in our code.

| Name/Test  | Original, 8 thread | Original, 64 thread | 10K, 8 thread | 10K, 64 thread |
| ------------- | ------------- | ------------- | ------------- | ------------- |
| lehuyduc  | **1.756 s ±  0.013 s**  | **403 ms ±   6.3 ms**  | 2.463 s ±  0.021 s  | **708.6 ms ±   3.8 ms** |
| artsiomkorzun  | 1.896 s ±  0.009 s  | 485.7 ms ±   3.4 ms | **2.419 s ±  0.008 s**  | 0.782 s ±  0.012 s  |
| royvanrijn  | 2.8 s ±  0.018 s  | 671.9 ms ±   5.8 ms  | 4.643 s ±  0.017 s  | 1.309 s ±  0.014 s |
| thomaswue  | 2.069 s ±  0.021 s  | 456.4 ms ±   8.2 ms  | 3.938 s ±  0.022 s  | 1.225 s ±  0.012 s  |

You can see the raw results in folder `benchmark_results`, files `other_artsi_7502p`, `other_thomas_7502p`, `other_royvanrijn_7502p`, `valid20_7502p`, `valid20_7502p_10k`

**Other submission**
There's a super fast non-compliant solution at: https://curiouscoding.nl/posts/1brc/ 
It doesn't work with all inputs like required, but is extremely fast and has very creative ideas.

----------------------
------------------------------------
I also benchmark RAM copy bandwidth to compare more. `copy_bandwidth.cpp` uses threads to copy a large `mmap` array into RAM array multiple times.

**RAM copy bandwidth on AMD 5995WX, 128 threads**
```
Bandwidth = 7.56104e+10 byte/s
```
`Parallel process file cost = 152.155ms` => 90.7 GB / s => **120% RAM copy speed**

**RAM copy bandwidth on AMD EPYC 7502, 64 threads**
```
Bandwidth = 5.79936e+10 byte/s
```
`Parallel process file cost = 314.445ms` => 43.9 GB / s => **75.7% RAM copy speed**, quite slower than 2 other CPUs

**RAM copy bandwidth on AMD 2950X, 32 threads**
```
Bandwidth = 2.42118e+10 byte/s
```
`Parallel process file cost = 426.903ms` => 32.3 GB / s => **133% RAM copy speed !!!**

So we've just parsed and processed 1 billion lines of text faster than just copying it. That's because writing into RAM is slow, and we don't write a lot into RAM because most of our hash bins are inside L1/L2 cache. I should find a better comparison.

**Main ideas:**
------------------------------------
- Unsigned int overflow hashing: cheapest hash method possible.
- SIMD to find separator `;`
- SIMD hashing
- SIMD for string comparison in hash table probing
- Parse number as int instead of float 
- Notice properties of actual data
- + 99% of station names has `length <= 16`, use compiler hint + implement SIMD for this specific case. If length > 16, use a fallback => still meet requirements of `MAX_KEY_LENGTH = 100`
- + `-99.9 <= temperature <= 99.9` guaranteed, use special code using this property
- Use mmap for fast file reading
- Use multithreading for both parsing the file, and aggregating the data
- Other random tricks (intentional ordering of variable assignments)
- **Automatic RAM disk**: the contest assumes the file is in RAM, not disk. This is done automatically on Linux if you read the file using `mmap` once, then run the program again. Without this rule, all solutions will be completely different.

**Others**
~~There's a potential out-of-range-access exploit in the code. It's left as exercise for the reader.~~ 

I optimize the code for hyper threading. For example with a 16c32t CPU, if a change improves performance when running 32 threads but slightly decreases performance at 16, I will keep that change. Disabling HT will increase performance at the same thread count (maybe even 20-25%), so there are some situations where it's the correct choice.